{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.3.0 in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (2.3.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.3.0) (1.6.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.3.0) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.3.0) (3.3.0)\n",
      "Requirement already satisfied: scipy==1.4.1 in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.3.0) (1.4.1)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.3.0) (1.1.2)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.3.0) (3.19.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.3.0) (0.36.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.3.0) (1.41.1)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.3.0) (1.18.5)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.3.0) (2.7.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.3.0) (2.3.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.3.0) (0.3.3)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.3.0) (2.10.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.3.0) (1.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.3.0) (1.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.3.0) (1.12.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from tensorflow==2.3.0) (0.2.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.25.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.8.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (52.0.0.post20210125)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.3.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.3.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.6.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.26.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.1.1)\n",
      "Requirement already satisfied: gym in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (0.21.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from gym) (1.18.5)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from gym) (1.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.3.0\n",
    "!pip install gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup the Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///Users/georgio/Documents/GitHub/gym_MLAA\n",
      "Requirement already satisfied: gym in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from gym-MLAA==0.1) (0.21.0)\n",
      "Requirement already satisfied: pygame in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from gym-MLAA==0.1) (2.1.2)\n",
      "Requirement already satisfied: numpy in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from gym-MLAA==0.1) (1.18.5)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /Users/georgio/opt/anaconda3/lib/python3.8/site-packages (from gym->gym-MLAA==0.1) (1.6.0)\n",
      "Installing collected packages: gym-MLAA\n",
      "  Attempting uninstall: gym-MLAA\n",
      "    Found existing installation: gym-MLAA 0.1\n",
      "    Uninstalling gym-MLAA-0.1:\n",
      "      Successfully uninstalled gym-MLAA-0.1\n",
      "  Running setup.py develop for gym-MLAA\n",
      "Successfully installed gym-MLAA\n"
     ]
    }
   ],
   "source": [
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym \n",
    "import random\n",
    "import sys\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the game environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.8.8)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "Box([0 0], [4 4], (2,), int64)\n",
      "Discrete(4)\n"
     ]
    }
   ],
   "source": [
    "import gym_MLAA\n",
    "env = gym.make('maze-random-5x5-v0')\n",
    "#env = gym.make('maze-random-10x10-plus-v0')\n",
    "#env = gym.make(maze-random-30x30-plus-v0)\n",
    "\n",
    "states = env.observation_space\n",
    "actions = env.action_space\n",
    "print(states)\n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Env and Training Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Defining the environment related constants\n",
    "'''\n",
    "# Number of discrete states (bucket) per state dimension\n",
    "MAZE_SIZE = tuple((env.observation_space.high + np.ones(env.observation_space.shape)).astype(int))\n",
    "NUM_BUCKETS = MAZE_SIZE  # one bucket per grid\n",
    "\n",
    "# Number of discrete actions\n",
    "NUM_ACTIONS = env.action_space.n  # [\"N\", \"S\", \"E\", \"W\"]\n",
    "# Bounds for each discrete state\n",
    "STATE_BOUNDS = list(zip(env.observation_space.low, env.observation_space.high))\n",
    "\n",
    "'''\n",
    "Learning related constants\n",
    "'''\n",
    "MIN_EXPLORE_RATE = 0.001\n",
    "MIN_LEARNING_RATE = 0.2\n",
    "DECAY_FACTOR = np.prod(MAZE_SIZE, dtype=float) / 10.0\n",
    "\n",
    "'''\n",
    "Defining the simulation related constants\n",
    "'''\n",
    "NUM_EPISODES = 50000\n",
    "MAX_T = np.prod(MAZE_SIZE, dtype=int) * 100\n",
    "STREAK_TO_END = 100\n",
    "SOLVED_T = np.prod(MAZE_SIZE, dtype=int)\n",
    "#DEBUG_MODE = 0\n",
    "RENDER_MAZE = True\n",
    "ENABLE_RECORDING = True\n",
    "\n",
    "'''\n",
    "Creating a Q-Table for each state-action pair\n",
    "'''\n",
    "q_table = np.zeros(NUM_BUCKETS + (NUM_ACTIONS,), dtype=float)\n",
    "\n",
    "'''\n",
    "Begin simulation\n",
    "'''\n",
    "recording_folder = \"/tmp/maze_q_learning\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state, explore_rate):\n",
    "    # Select a random action\n",
    "    if random.random() < explore_rate:\n",
    "        action = env.action_space.sample()\n",
    "    # Select the action with the highest q\n",
    "    else:\n",
    "        action = int(np.argmax(q_table[state]))\n",
    "    return action\n",
    "\n",
    "\n",
    "def get_explore_rate(t):\n",
    "    return max(MIN_EXPLORE_RATE, min(0.8, 1.0 - math.log10((t+1)/DECAY_FACTOR)))\n",
    "\n",
    "\n",
    "def get_learning_rate(t):\n",
    "    return max(MIN_LEARNING_RATE, min(0.8, 1.0 - math.log10((t+1)/DECAY_FACTOR)))\n",
    "\n",
    "\n",
    "def state_to_bucket(state):\n",
    "    bucket_indice = []\n",
    "    for i in range(len(state)):\n",
    "        if state[i] <= STATE_BOUNDS[i][0]:\n",
    "            bucket_index = 0\n",
    "        elif state[i] >= STATE_BOUNDS[i][1]:\n",
    "            bucket_index = NUM_BUCKETS[i] - 1\n",
    "        else:\n",
    "            # Mapping the state bounds to the bucket array\n",
    "            bound_width = STATE_BOUNDS[i][1] - STATE_BOUNDS[i][0]\n",
    "            offset = (NUM_BUCKETS[i]-1)*STATE_BOUNDS[i][0]/bound_width\n",
    "            scaling = (NUM_BUCKETS[i]-1)/bound_width\n",
    "            bucket_index = int(round(scaling*state[i] - offset))\n",
    "        bucket_indice.append(bucket_index)\n",
    "    return tuple(bucket_indice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_timeSteps_list = []\n",
    "Q_TotalReward_list = []\n",
    "Q_Episodes_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 finished after 15.000000 time steps with total reward = 0.472000 (streak 0).\n",
      "Episode 1 finished after 22.000000 time steps with total reward = 0.444000 (streak 1).\n",
      "Episode 2 finished after 93.000000 time steps with total reward = -1.712000 (streak 2).\n",
      "Episode 3 finished after 17.000000 time steps with total reward = 0.464000 (streak 0).\n",
      "Episode 4 finished after 17.000000 time steps with total reward = 0.536000 (streak 1).\n",
      "Episode 5 finished after 54.000000 time steps with total reward = -0.080000 (streak 2).\n",
      "Episode 6 finished after 241.000000 time steps with total reward = -4.788000 (streak 0).\n",
      "Episode 7 finished after 214.000000 time steps with total reward = -4.248000 (streak 0).\n",
      "Episode 8 finished after 150.000000 time steps with total reward = -3.092000 (streak 0).\n",
      "Episode 9 finished after 272.000000 time steps with total reward = -5.884000 (streak 0).\n",
      "Episode 10 finished after 207.000000 time steps with total reward = -3.896000 (streak 0).\n",
      "Episode 11 finished after 145.000000 time steps with total reward = -2.856000 (streak 0).\n",
      "Episode 12 finished after 13.000000 time steps with total reward = 0.588000 (streak 0).\n",
      "Episode 13 finished after 113.000000 time steps with total reward = -1.072000 (streak 1).\n",
      "Episode 14 finished after 231.000000 time steps with total reward = -2.012000 (streak 0).\n",
      "Episode 15 finished after 33.000000 time steps with total reward = 0.616000 (streak 0).\n",
      "Episode 16 finished after 128.000000 time steps with total reward = -3.040000 (streak 0).\n",
      "Episode 17 finished after 90.000000 time steps with total reward = -2.420000 (streak 0).\n",
      "Episode 18 finished after 136.000000 time steps with total reward = -0.912000 (streak 0).\n",
      "Episode 19 finished after 83.000000 time steps with total reward = -0.988000 (streak 0).\n",
      "Episode 20 finished after 316.000000 time steps with total reward = -4.584000 (streak 0).\n",
      "Episode 21 finished after 295.000000 time steps with total reward = -5.436000 (streak 0).\n",
      "Episode 22 finished after 30.000000 time steps with total reward = 0.232000 (streak 0).\n",
      "Episode 23 finished after 263.000000 time steps with total reward = -5.740000 (streak 0).\n",
      "Episode 24 finished after 13.000000 time steps with total reward = 0.660000 (streak 0).\n",
      "Episode 25 finished after 5.000000 time steps with total reward = 0.836000 (streak 1).\n",
      "Episode 26 finished after 22.000000 time steps with total reward = 0.192000 (streak 2).\n",
      "Episode 27 finished after 41.000000 time steps with total reward = -0.496000 (streak 3).\n",
      "Episode 28 finished after 18.000000 time steps with total reward = 0.352000 (streak 0).\n",
      "Episode 29 finished after 19.000000 time steps with total reward = 0.312000 (streak 1).\n",
      "Episode 30 finished after 209.000000 time steps with total reward = -4.912000 (streak 2).\n",
      "Episode 31 finished after 805.000000 time steps with total reward = -17.088000 (streak 0).\n",
      "Episode 32 finished after 141.000000 time steps with total reward = -1.004000 (streak 0).\n",
      "Episode 33 finished after 22.000000 time steps with total reward = 0.156000 (streak 0).\n",
      "Episode 34 finished after 22.000000 time steps with total reward = 0.156000 (streak 1).\n",
      "Episode 35 finished after 286.000000 time steps with total reward = -5.148000 (streak 2).\n",
      "Episode 36 finished after 40.000000 time steps with total reward = -0.204000 (streak 0).\n",
      "Episode 37 finished after 44.000000 time steps with total reward = -0.472000 (streak 0).\n",
      "Episode 38 finished after 122.000000 time steps with total reward = -2.116000 (streak 0).\n",
      "Episode 39 finished after 25.000000 time steps with total reward = 0.072000 (streak 0).\n",
      "Episode 40 finished after 5.000000 time steps with total reward = 0.836000 (streak 1).\n",
      "Episode 41 finished after 30.000000 time steps with total reward = 0.232000 (streak 2).\n",
      "Episode 42 finished after 36.000000 time steps with total reward = 0.100000 (streak 0).\n",
      "Episode 43 finished after 225.000000 time steps with total reward = -5.372000 (streak 0).\n",
      "Episode 44 finished after 9.000000 time steps with total reward = 0.712000 (streak 0).\n",
      "Episode 45 finished after 43.000000 time steps with total reward = -0.576000 (streak 1).\n",
      "Episode 46 finished after 8.000000 time steps with total reward = 0.752000 (streak 0).\n",
      "Episode 47 finished after 26.000000 time steps with total reward = 0.068000 (streak 1).\n",
      "Episode 48 finished after 30.000000 time steps with total reward = -0.092000 (streak 0).\n",
      "Episode 49 finished after 8.000000 time steps with total reward = 0.752000 (streak 0).\n",
      "Episode 50 finished after 39.000000 time steps with total reward = -0.452000 (streak 1).\n",
      "Episode 51 finished after 39.000000 time steps with total reward = -0.380000 (streak 0).\n",
      "Episode 52 finished after 15.000000 time steps with total reward = 0.508000 (streak 0).\n",
      "Episode 53 finished after 56.000000 time steps with total reward = 0.272000 (streak 1).\n",
      "Episode 54 finished after 15.000000 time steps with total reward = 0.508000 (streak 0).\n",
      "Episode 55 finished after 20.000000 time steps with total reward = 0.344000 (streak 1).\n",
      "Episode 56 finished after 20.000000 time steps with total reward = 0.344000 (streak 2).\n",
      "Episode 57 finished after 13.000000 time steps with total reward = 0.588000 (streak 3).\n",
      "Episode 58 finished after 40.000000 time steps with total reward = 0.012000 (streak 4).\n",
      "Episode 59 finished after 38.000000 time steps with total reward = -0.304000 (streak 0).\n",
      "Episode 60 finished after 35.000000 time steps with total reward = -0.292000 (streak 0).\n",
      "Episode 61 finished after 8.000000 time steps with total reward = 0.752000 (streak 0).\n",
      "Episode 62 finished after 31.000000 time steps with total reward = -0.132000 (streak 1).\n",
      "Episode 63 finished after 31.000000 time steps with total reward = -0.132000 (streak 0).\n",
      "Episode 64 finished after 33.000000 time steps with total reward = -0.212000 (streak 0).\n",
      "Episode 65 finished after 34.000000 time steps with total reward = -0.252000 (streak 0).\n",
      "Episode 66 finished after 11.000000 time steps with total reward = 0.632000 (streak 0).\n",
      "Episode 67 finished after 51.000000 time steps with total reward = -0.284000 (streak 1).\n",
      "Episode 68 finished after 9.000000 time steps with total reward = 0.712000 (streak 0).\n",
      "Episode 69 finished after 15.000000 time steps with total reward = 0.508000 (streak 1).\n",
      "Episode 70 finished after 27.000000 time steps with total reward = 0.028000 (streak 2).\n",
      "Episode 71 finished after 46.000000 time steps with total reward = -0.660000 (streak 0).\n",
      "Episode 72 finished after 7.000000 time steps with total reward = 0.792000 (streak 0).\n",
      "Episode 73 finished after 28.000000 time steps with total reward = -0.048000 (streak 1).\n",
      "Episode 74 finished after 56.000000 time steps with total reward = -0.988000 (streak 0).\n",
      "Episode 75 finished after 7.000000 time steps with total reward = 0.792000 (streak 0).\n",
      "Episode 76 finished after 7.000000 time steps with total reward = 0.792000 (streak 1).\n",
      "Episode 77 finished after 7.000000 time steps with total reward = 0.792000 (streak 2).\n",
      "Episode 78 finished after 7.000000 time steps with total reward = 0.792000 (streak 3).\n",
      "Episode 79 finished after 7.000000 time steps with total reward = 0.792000 (streak 4).\n",
      "Episode 80 finished after 7.000000 time steps with total reward = 0.792000 (streak 5).\n",
      "Episode 81 finished after 7.000000 time steps with total reward = 0.792000 (streak 6).\n",
      "Episode 82 finished after 7.000000 time steps with total reward = 0.792000 (streak 7).\n",
      "Episode 83 finished after 7.000000 time steps with total reward = 0.792000 (streak 8).\n",
      "Episode 84 finished after 7.000000 time steps with total reward = 0.792000 (streak 9).\n",
      "Episode 85 finished after 7.000000 time steps with total reward = 0.792000 (streak 10).\n",
      "Episode 86 finished after 7.000000 time steps with total reward = 0.792000 (streak 11).\n",
      "Episode 87 finished after 7.000000 time steps with total reward = 0.792000 (streak 12).\n",
      "Episode 88 finished after 7.000000 time steps with total reward = 0.792000 (streak 13).\n",
      "Episode 89 finished after 7.000000 time steps with total reward = 0.792000 (streak 14).\n",
      "Episode 90 finished after 7.000000 time steps with total reward = 0.792000 (streak 15).\n",
      "Episode 91 finished after 7.000000 time steps with total reward = 0.792000 (streak 16).\n",
      "Episode 92 finished after 7.000000 time steps with total reward = 0.792000 (streak 17).\n",
      "Episode 93 finished after 7.000000 time steps with total reward = 0.792000 (streak 18).\n",
      "Episode 94 finished after 7.000000 time steps with total reward = 0.792000 (streak 19).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 95 finished after 7.000000 time steps with total reward = 0.792000 (streak 20).\n",
      "Episode 96 finished after 7.000000 time steps with total reward = 0.792000 (streak 21).\n",
      "Episode 97 finished after 7.000000 time steps with total reward = 0.792000 (streak 22).\n",
      "Episode 98 finished after 7.000000 time steps with total reward = 0.792000 (streak 23).\n",
      "Episode 99 finished after 7.000000 time steps with total reward = 0.792000 (streak 24).\n",
      "Episode 100 finished after 7.000000 time steps with total reward = 0.792000 (streak 25).\n",
      "Episode 101 finished after 7.000000 time steps with total reward = 0.792000 (streak 26).\n",
      "Episode 102 finished after 7.000000 time steps with total reward = 0.792000 (streak 27).\n",
      "Episode 103 finished after 7.000000 time steps with total reward = 0.792000 (streak 28).\n",
      "Episode 104 finished after 7.000000 time steps with total reward = 0.792000 (streak 29).\n",
      "Episode 105 finished after 7.000000 time steps with total reward = 0.792000 (streak 30).\n",
      "Episode 106 finished after 7.000000 time steps with total reward = 0.792000 (streak 31).\n",
      "Episode 107 finished after 7.000000 time steps with total reward = 0.792000 (streak 32).\n",
      "Episode 108 finished after 7.000000 time steps with total reward = 0.792000 (streak 33).\n",
      "Episode 109 finished after 7.000000 time steps with total reward = 0.792000 (streak 34).\n",
      "Episode 110 finished after 7.000000 time steps with total reward = 0.792000 (streak 35).\n",
      "Episode 111 finished after 7.000000 time steps with total reward = 0.792000 (streak 36).\n",
      "Episode 112 finished after 7.000000 time steps with total reward = 0.792000 (streak 37).\n",
      "Episode 113 finished after 7.000000 time steps with total reward = 0.792000 (streak 38).\n",
      "Episode 114 finished after 7.000000 time steps with total reward = 0.792000 (streak 39).\n",
      "Episode 115 finished after 7.000000 time steps with total reward = 0.792000 (streak 40).\n",
      "Episode 116 finished after 7.000000 time steps with total reward = 0.792000 (streak 41).\n",
      "Episode 117 finished after 7.000000 time steps with total reward = 0.792000 (streak 42).\n",
      "Episode 118 finished after 7.000000 time steps with total reward = 0.792000 (streak 43).\n",
      "Episode 119 finished after 7.000000 time steps with total reward = 0.792000 (streak 44).\n",
      "Episode 120 finished after 7.000000 time steps with total reward = 0.792000 (streak 45).\n",
      "Episode 121 finished after 9.000000 time steps with total reward = 0.748000 (streak 46).\n",
      "Episode 122 finished after 7.000000 time steps with total reward = 0.792000 (streak 47).\n",
      "Episode 123 finished after 7.000000 time steps with total reward = 0.792000 (streak 48).\n",
      "Episode 124 finished after 7.000000 time steps with total reward = 0.792000 (streak 49).\n",
      "Episode 125 finished after 7.000000 time steps with total reward = 0.792000 (streak 50).\n",
      "Episode 126 finished after 7.000000 time steps with total reward = 0.792000 (streak 51).\n",
      "Episode 127 finished after 7.000000 time steps with total reward = 0.792000 (streak 52).\n",
      "Episode 128 finished after 7.000000 time steps with total reward = 0.792000 (streak 53).\n",
      "Episode 129 finished after 7.000000 time steps with total reward = 0.792000 (streak 54).\n",
      "Episode 130 finished after 7.000000 time steps with total reward = 0.792000 (streak 55).\n",
      "Episode 131 finished after 7.000000 time steps with total reward = 0.792000 (streak 56).\n",
      "Episode 132 finished after 7.000000 time steps with total reward = 0.792000 (streak 57).\n",
      "Episode 133 finished after 7.000000 time steps with total reward = 0.792000 (streak 58).\n",
      "Episode 134 finished after 7.000000 time steps with total reward = 0.792000 (streak 59).\n",
      "Episode 135 finished after 7.000000 time steps with total reward = 0.792000 (streak 60).\n",
      "Episode 136 finished after 7.000000 time steps with total reward = 0.792000 (streak 61).\n",
      "Episode 137 finished after 7.000000 time steps with total reward = 0.792000 (streak 62).\n",
      "Episode 138 finished after 7.000000 time steps with total reward = 0.792000 (streak 63).\n",
      "Episode 139 finished after 7.000000 time steps with total reward = 0.792000 (streak 64).\n",
      "Episode 140 finished after 7.000000 time steps with total reward = 0.792000 (streak 65).\n",
      "Episode 141 finished after 7.000000 time steps with total reward = 0.792000 (streak 66).\n",
      "Episode 142 finished after 7.000000 time steps with total reward = 0.792000 (streak 67).\n",
      "Episode 143 finished after 7.000000 time steps with total reward = 0.792000 (streak 68).\n",
      "Episode 144 finished after 7.000000 time steps with total reward = 0.792000 (streak 69).\n",
      "Episode 145 finished after 7.000000 time steps with total reward = 0.792000 (streak 70).\n",
      "Episode 146 finished after 7.000000 time steps with total reward = 0.792000 (streak 71).\n",
      "Episode 147 finished after 7.000000 time steps with total reward = 0.792000 (streak 72).\n",
      "Episode 148 finished after 7.000000 time steps with total reward = 0.792000 (streak 73).\n",
      "Episode 149 finished after 7.000000 time steps with total reward = 0.792000 (streak 74).\n",
      "Episode 150 finished after 7.000000 time steps with total reward = 0.792000 (streak 75).\n",
      "Episode 151 finished after 7.000000 time steps with total reward = 0.792000 (streak 76).\n",
      "Episode 152 finished after 7.000000 time steps with total reward = 0.792000 (streak 77).\n",
      "Episode 153 finished after 7.000000 time steps with total reward = 0.792000 (streak 78).\n",
      "Episode 154 finished after 7.000000 time steps with total reward = 0.792000 (streak 79).\n",
      "Episode 155 finished after 7.000000 time steps with total reward = 0.792000 (streak 80).\n",
      "Episode 156 finished after 7.000000 time steps with total reward = 0.792000 (streak 81).\n",
      "Episode 157 finished after 7.000000 time steps with total reward = 0.792000 (streak 82).\n",
      "Episode 158 finished after 7.000000 time steps with total reward = 0.792000 (streak 83).\n",
      "Episode 159 finished after 7.000000 time steps with total reward = 0.792000 (streak 84).\n",
      "Episode 160 finished after 7.000000 time steps with total reward = 0.792000 (streak 85).\n",
      "Episode 161 finished after 7.000000 time steps with total reward = 0.792000 (streak 86).\n",
      "Episode 162 finished after 7.000000 time steps with total reward = 0.792000 (streak 87).\n",
      "Episode 163 finished after 7.000000 time steps with total reward = 0.792000 (streak 88).\n",
      "Episode 164 finished after 7.000000 time steps with total reward = 0.792000 (streak 89).\n",
      "Episode 165 finished after 7.000000 time steps with total reward = 0.792000 (streak 90).\n",
      "Episode 166 finished after 7.000000 time steps with total reward = 0.792000 (streak 91).\n",
      "Episode 167 finished after 7.000000 time steps with total reward = 0.792000 (streak 92).\n",
      "Episode 168 finished after 7.000000 time steps with total reward = 0.792000 (streak 93).\n",
      "Episode 169 finished after 7.000000 time steps with total reward = 0.792000 (streak 94).\n",
      "Episode 170 finished after 7.000000 time steps with total reward = 0.792000 (streak 95).\n",
      "Episode 171 finished after 7.000000 time steps with total reward = 0.792000 (streak 96).\n",
      "Episode 172 finished after 7.000000 time steps with total reward = 0.792000 (streak 97).\n",
      "Episode 173 finished after 7.000000 time steps with total reward = 0.792000 (streak 98).\n",
      "Episode 174 finished after 7.000000 time steps with total reward = 0.792000 (streak 99).\n",
      "Episode 175 finished after 7.000000 time steps with total reward = 0.792000 (streak 100).\n"
     ]
    }
   ],
   "source": [
    "# Instantiating the learning related parameters\n",
    "learning_rate = get_learning_rate(0)\n",
    "explore_rate = get_explore_rate(0)\n",
    "discount_factor = 0.99\n",
    "\n",
    "num_streaks = 0\n",
    "\n",
    "# Render tha maze\n",
    "env.render()\n",
    "\n",
    "for episode in range(NUM_EPISODES):\n",
    "\n",
    "    # Reset the environment\n",
    "    obv = env.reset()\n",
    "\n",
    "    # the initial state\n",
    "    state_0 = state_to_bucket(obv)\n",
    "    action = select_action(state_0, explore_rate)\n",
    "    total_reward = 0\n",
    "\n",
    "    for t in range(MAX_T):\n",
    "\n",
    "        # execute the action\n",
    "        obv, reward, done, _ = env.step(action)\n",
    "\n",
    "        # Observe the result\n",
    "        state = state_to_bucket(obv)\n",
    "        total_reward += reward\n",
    "        \n",
    "        # Select an action\n",
    "        action = select_action(state_0, explore_rate)\n",
    "\n",
    "        # Update the Q based on the result\n",
    "        best_q = np.amax(q_table[state])\n",
    "        q_table[state_0 + (action,)] += learning_rate * (reward + discount_factor * (best_q) - q_table[state_0 + (action,)])\n",
    "        #q_table[state_0 + (action,)] += learning_rate * (reward + discount_factor * q_table[state_0 + (action,)] - q_table[state_0 + (action,)])\n",
    "        \n",
    "        # Setting up for the next iteration\n",
    "        state_0 = state\n",
    "\n",
    "        # Render tha maze\n",
    "        if RENDER_MAZE:\n",
    "            env.render()\n",
    "\n",
    "        if env.is_game_over():\n",
    "            sys.exit()\n",
    "\n",
    "        if done:\n",
    "            print(\"Episode %d finished after %f time steps with total reward = %f (streak %d).\"\n",
    "                  % (episode, t, total_reward, num_streaks))\n",
    "            Q_Episodes_list.append(episode)\n",
    "            Q_timeSteps_list.append(t)\n",
    "            Q_TotalReward_list.append(total_reward)\n",
    "            \n",
    "            if t <= SOLVED_T:\n",
    "                num_streaks += 1\n",
    "            else:\n",
    "                num_streaks = 0\n",
    "            break\n",
    "\n",
    "        elif t >= MAX_T - 1:\n",
    "            print(\"Episode %d timed out at %d with total reward = %f.\"\n",
    "                  % (episode, t, total_reward))\n",
    "\n",
    "    # It's considered done when it's solved over 120 times consecutively\n",
    "    if num_streaks > STREAK_TO_END:\n",
    "        break\n",
    "\n",
    "    # Update parameters\n",
    "    explore_rate = get_explore_rate(episode)\n",
    "    learning_rate = get_learning_rate(episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4720000000000001, 0.44400000000000006, -1.7120000000000015, 0.4640000000000001, 0.536, -0.08000000000000052, -4.787999999999995, -4.248000000000002, -3.0920000000000023, -5.8839999999999835, -3.8959999999999946, -2.8560000000000025, 0.5880000000000001, -1.0720000000000014, -2.0120000000000022, 0.616, -3.0400000000000027, -2.420000000000002, -0.9120000000000013, -0.9880000000000011, -4.583999999999988, -5.435999999999999, 0.23199999999999987, -5.739999999999976, 0.66, 0.836, 0.19199999999999984, -0.49600000000000066, 0.352, 0.31199999999999994, -4.911999999999993, -17.087999999999738, -1.004000000000001, 0.1559999999999998, 0.1559999999999998, -5.1479999999999855, -0.2040000000000004, -0.47200000000000064, -2.116000000000002, 0.07199999999999973, 0.836, 0.23199999999999987, 0.09999999999999976, -5.371999999999986, 0.712, -0.5760000000000007, 0.752, 0.06799999999999973, -0.0920000000000003, 0.752, -0.4520000000000006, -0.38000000000000056, 0.5080000000000001, 0.2719999999999997, 0.5080000000000001, 0.344, 0.344, 0.5880000000000001, 0.011999999999999678, -0.3040000000000005, -0.2920000000000005, 0.752, -0.13200000000000034, -0.13200000000000034, -0.2120000000000004, -0.25200000000000045, 0.632, -0.2840000000000005, 0.712, 0.5080000000000001, 0.027999999999999692, -0.6600000000000008, 0.792, -0.048000000000000265, -0.9880000000000011, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.748, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792, 0.792]\n",
      "[15, 22, 93, 17, 17, 54, 241, 214, 150, 272, 207, 145, 13, 113, 231, 33, 128, 90, 136, 83, 316, 295, 30, 263, 13, 5, 22, 41, 18, 19, 209, 805, 141, 22, 22, 286, 40, 44, 122, 25, 5, 30, 36, 225, 9, 43, 8, 26, 30, 8, 39, 39, 15, 56, 15, 20, 20, 13, 40, 38, 35, 8, 31, 31, 33, 34, 11, 51, 9, 15, 27, 46, 7, 28, 56, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175]\n"
     ]
    }
   ],
   "source": [
    "print(Q_TotalReward_list)\n",
    "print(Q_timeSteps_list)\n",
    "print(Q_Episodes_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Q-Learning Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# importing the required module\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# plotting the points\n",
    "plt.plot(Q_Episodes_list, Q_TotalReward_list)\n",
    " \n",
    "# naming the x axis\n",
    "plt.xlabel('Episodes')\n",
    "# naming the y axis\n",
    "plt.ylabel('Total Reward')\n",
    " \n",
    "# giving a title to my graph\n",
    "#plt.title('My first graph!')\n",
    " \n",
    "# function to show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SARSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_timeSteps_list = []\n",
    "S_TotalReward_list = []\n",
    "S_Episodes_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 finished after 14.000000 time steps with total reward = 0.548000 (streak 0).\n",
      "Episode 1 finished after 117.000000 time steps with total reward = -1.124000 (streak 1).\n",
      "Episode 2 finished after 52.000000 time steps with total reward = -0.612000 (streak 0).\n",
      "Episode 3 finished after 46.000000 time steps with total reward = 0.096000 (streak 0).\n",
      "Episode 4 finished after 112.000000 time steps with total reward = -1.860000 (streak 0).\n",
      "Episode 5 finished after 22.000000 time steps with total reward = 0.588000 (streak 0).\n",
      "Episode 6 finished after 41.000000 time steps with total reward = 0.476000 (streak 1).\n",
      "Episode 7 finished after 45.000000 time steps with total reward = 0.208000 (streak 0).\n",
      "Episode 8 finished after 92.000000 time steps with total reward = -1.276000 (streak 0).\n",
      "Episode 9 finished after 23.000000 time steps with total reward = 0.368000 (streak 0).\n",
      "Episode 10 finished after 37.000000 time steps with total reward = -0.192000 (streak 1).\n",
      "Episode 11 finished after 5.000000 time steps with total reward = 0.836000 (streak 0).\n",
      "Episode 12 finished after 30.000000 time steps with total reward = 0.628000 (streak 1).\n",
      "Episode 13 finished after 15.000000 time steps with total reward = 0.724000 (streak 0).\n",
      "Episode 14 finished after 5.000000 time steps with total reward = 0.836000 (streak 1).\n",
      "Episode 15 finished after 6.000000 time steps with total reward = 0.796000 (streak 2).\n",
      "Episode 16 finished after 5.000000 time steps with total reward = 0.836000 (streak 3).\n",
      "Episode 17 finished after 102.000000 time steps with total reward = 0.088000 (streak 4).\n",
      "Episode 18 finished after 5.000000 time steps with total reward = 0.836000 (streak 0).\n",
      "Episode 19 finished after 5.000000 time steps with total reward = 0.836000 (streak 1).\n",
      "Episode 20 finished after 5.000000 time steps with total reward = 0.836000 (streak 2).\n",
      "Episode 21 finished after 5.000000 time steps with total reward = 0.836000 (streak 3).\n",
      "Episode 22 finished after 5.000000 time steps with total reward = 0.836000 (streak 4).\n",
      "Episode 23 finished after 5.000000 time steps with total reward = 0.836000 (streak 5).\n",
      "Episode 24 finished after 5.000000 time steps with total reward = 0.836000 (streak 6).\n",
      "Episode 25 finished after 5.000000 time steps with total reward = 0.836000 (streak 7).\n",
      "Episode 26 finished after 5.000000 time steps with total reward = 0.836000 (streak 8).\n",
      "Episode 27 finished after 5.000000 time steps with total reward = 0.836000 (streak 9).\n",
      "Episode 28 finished after 5.000000 time steps with total reward = 0.836000 (streak 10).\n",
      "Episode 29 finished after 5.000000 time steps with total reward = 0.836000 (streak 11).\n",
      "Episode 30 finished after 5.000000 time steps with total reward = 0.836000 (streak 12).\n",
      "Episode 31 finished after 5.000000 time steps with total reward = 0.836000 (streak 13).\n",
      "Episode 32 finished after 5.000000 time steps with total reward = 0.836000 (streak 14).\n",
      "Episode 33 finished after 5.000000 time steps with total reward = 0.836000 (streak 15).\n",
      "Episode 34 finished after 5.000000 time steps with total reward = 0.836000 (streak 16).\n",
      "Episode 35 finished after 5.000000 time steps with total reward = 0.836000 (streak 17).\n",
      "Episode 36 finished after 5.000000 time steps with total reward = 0.836000 (streak 18).\n",
      "Episode 37 finished after 5.000000 time steps with total reward = 0.836000 (streak 19).\n",
      "Episode 38 finished after 5.000000 time steps with total reward = 0.836000 (streak 20).\n",
      "Episode 39 finished after 5.000000 time steps with total reward = 0.836000 (streak 21).\n",
      "Episode 40 finished after 5.000000 time steps with total reward = 0.836000 (streak 22).\n",
      "Episode 41 finished after 5.000000 time steps with total reward = 0.836000 (streak 23).\n",
      "Episode 42 finished after 5.000000 time steps with total reward = 0.836000 (streak 24).\n",
      "Episode 43 finished after 5.000000 time steps with total reward = 0.836000 (streak 25).\n",
      "Episode 44 finished after 5.000000 time steps with total reward = 0.836000 (streak 26).\n",
      "Episode 45 finished after 5.000000 time steps with total reward = 0.836000 (streak 27).\n",
      "Episode 46 finished after 5.000000 time steps with total reward = 0.836000 (streak 28).\n",
      "Episode 47 finished after 5.000000 time steps with total reward = 0.836000 (streak 29).\n",
      "Episode 48 finished after 5.000000 time steps with total reward = 0.836000 (streak 30).\n",
      "Episode 49 finished after 5.000000 time steps with total reward = 0.836000 (streak 31).\n",
      "Episode 50 finished after 5.000000 time steps with total reward = 0.836000 (streak 32).\n",
      "Episode 51 finished after 5.000000 time steps with total reward = 0.836000 (streak 33).\n",
      "Episode 52 finished after 5.000000 time steps with total reward = 0.836000 (streak 34).\n",
      "Episode 53 finished after 5.000000 time steps with total reward = 0.836000 (streak 35).\n",
      "Episode 54 finished after 5.000000 time steps with total reward = 0.836000 (streak 36).\n",
      "Episode 55 finished after 5.000000 time steps with total reward = 0.836000 (streak 37).\n",
      "Episode 56 finished after 5.000000 time steps with total reward = 0.836000 (streak 38).\n",
      "Episode 57 finished after 5.000000 time steps with total reward = 0.836000 (streak 39).\n",
      "Episode 58 finished after 5.000000 time steps with total reward = 0.836000 (streak 40).\n",
      "Episode 59 finished after 5.000000 time steps with total reward = 0.836000 (streak 41).\n",
      "Episode 60 finished after 5.000000 time steps with total reward = 0.836000 (streak 42).\n",
      "Episode 61 finished after 5.000000 time steps with total reward = 0.836000 (streak 43).\n",
      "Episode 62 finished after 5.000000 time steps with total reward = 0.836000 (streak 44).\n",
      "Episode 63 finished after 5.000000 time steps with total reward = 0.836000 (streak 45).\n",
      "Episode 64 finished after 5.000000 time steps with total reward = 0.836000 (streak 46).\n",
      "Episode 65 finished after 6.000000 time steps with total reward = 0.796000 (streak 47).\n",
      "Episode 66 finished after 5.000000 time steps with total reward = 0.836000 (streak 48).\n",
      "Episode 67 finished after 5.000000 time steps with total reward = 0.836000 (streak 49).\n",
      "Episode 68 finished after 5.000000 time steps with total reward = 0.836000 (streak 50).\n",
      "Episode 69 finished after 7.000000 time steps with total reward = 0.828000 (streak 51).\n",
      "Episode 70 finished after 9.000000 time steps with total reward = 0.820000 (streak 52).\n",
      "Episode 71 finished after 9.000000 time steps with total reward = 0.820000 (streak 53).\n",
      "Episode 72 finished after 8.000000 time steps with total reward = 0.824000 (streak 54).\n",
      "Episode 73 finished after 6.000000 time steps with total reward = 0.832000 (streak 55).\n",
      "Episode 74 finished after 6.000000 time steps with total reward = 0.832000 (streak 56).\n",
      "Episode 75 finished after 5.000000 time steps with total reward = 0.836000 (streak 57).\n",
      "Episode 76 finished after 5.000000 time steps with total reward = 0.836000 (streak 58).\n",
      "Episode 77 finished after 5.000000 time steps with total reward = 0.836000 (streak 59).\n",
      "Episode 78 finished after 5.000000 time steps with total reward = 0.836000 (streak 60).\n",
      "Episode 79 finished after 5.000000 time steps with total reward = 0.836000 (streak 61).\n",
      "Episode 80 finished after 5.000000 time steps with total reward = 0.836000 (streak 62).\n",
      "Episode 81 finished after 5.000000 time steps with total reward = 0.836000 (streak 63).\n",
      "Episode 82 finished after 5.000000 time steps with total reward = 0.836000 (streak 64).\n",
      "Episode 83 finished after 5.000000 time steps with total reward = 0.836000 (streak 65).\n",
      "Episode 84 finished after 5.000000 time steps with total reward = 0.836000 (streak 66).\n",
      "Episode 85 finished after 5.000000 time steps with total reward = 0.836000 (streak 67).\n",
      "Episode 86 finished after 5.000000 time steps with total reward = 0.836000 (streak 68).\n",
      "Episode 87 finished after 5.000000 time steps with total reward = 0.836000 (streak 69).\n",
      "Episode 88 finished after 5.000000 time steps with total reward = 0.836000 (streak 70).\n",
      "Episode 89 finished after 5.000000 time steps with total reward = 0.836000 (streak 71).\n",
      "Episode 90 finished after 5.000000 time steps with total reward = 0.836000 (streak 72).\n",
      "Episode 91 finished after 5.000000 time steps with total reward = 0.836000 (streak 73).\n",
      "Episode 92 finished after 5.000000 time steps with total reward = 0.836000 (streak 74).\n",
      "Episode 93 finished after 5.000000 time steps with total reward = 0.836000 (streak 75).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 94 finished after 5.000000 time steps with total reward = 0.836000 (streak 76).\n",
      "Episode 95 finished after 5.000000 time steps with total reward = 0.836000 (streak 77).\n",
      "Episode 96 finished after 5.000000 time steps with total reward = 0.836000 (streak 78).\n",
      "Episode 97 finished after 5.000000 time steps with total reward = 0.836000 (streak 79).\n",
      "Episode 98 finished after 5.000000 time steps with total reward = 0.836000 (streak 80).\n",
      "Episode 99 finished after 5.000000 time steps with total reward = 0.836000 (streak 81).\n",
      "Episode 100 finished after 5.000000 time steps with total reward = 0.836000 (streak 82).\n",
      "Episode 101 finished after 5.000000 time steps with total reward = 0.836000 (streak 83).\n",
      "Episode 102 finished after 5.000000 time steps with total reward = 0.836000 (streak 84).\n",
      "Episode 103 finished after 5.000000 time steps with total reward = 0.836000 (streak 85).\n",
      "Episode 104 finished after 5.000000 time steps with total reward = 0.836000 (streak 86).\n",
      "Episode 105 finished after 5.000000 time steps with total reward = 0.836000 (streak 87).\n",
      "Episode 106 finished after 5.000000 time steps with total reward = 0.836000 (streak 88).\n",
      "Episode 107 finished after 5.000000 time steps with total reward = 0.836000 (streak 89).\n",
      "Episode 108 finished after 5.000000 time steps with total reward = 0.836000 (streak 90).\n",
      "Episode 109 finished after 5.000000 time steps with total reward = 0.836000 (streak 91).\n",
      "Episode 110 finished after 5.000000 time steps with total reward = 0.836000 (streak 92).\n",
      "Episode 111 finished after 5.000000 time steps with total reward = 0.836000 (streak 93).\n",
      "Episode 112 finished after 5.000000 time steps with total reward = 0.836000 (streak 94).\n",
      "Episode 113 finished after 5.000000 time steps with total reward = 0.836000 (streak 95).\n",
      "Episode 114 finished after 5.000000 time steps with total reward = 0.836000 (streak 96).\n",
      "Episode 115 finished after 5.000000 time steps with total reward = 0.836000 (streak 97).\n",
      "Episode 116 finished after 5.000000 time steps with total reward = 0.836000 (streak 98).\n",
      "Episode 117 finished after 5.000000 time steps with total reward = 0.836000 (streak 99).\n",
      "Episode 118 finished after 5.000000 time steps with total reward = 0.836000 (streak 100).\n"
     ]
    }
   ],
   "source": [
    "# Instantiating the learning related parameters\n",
    "learning_rate = get_learning_rate(0)\n",
    "explore_rate = get_explore_rate(0)\n",
    "discount_factor = 0.99\n",
    "\n",
    "num_streaks = 0\n",
    "\n",
    "# Render tha maze\n",
    "env.render()\n",
    "\n",
    "for episode in range(NUM_EPISODES):\n",
    "\n",
    "    # Reset the environment\n",
    "    obv = env.reset()\n",
    "\n",
    "    # the initial state\n",
    "    state_0 = state_to_bucket(obv)\n",
    "    total_reward = 0\n",
    "\n",
    "    for t in range(MAX_T):\n",
    "\n",
    "        # execute the action\n",
    "        obv, reward, done, _ = env.step(action)\n",
    "\n",
    "        # Observe the result\n",
    "        state = state_to_bucket(obv)\n",
    "        total_reward += reward\n",
    "        \n",
    "        # Select an action\n",
    "        action_new = select_action(state, explore_rate)\n",
    "\n",
    "        # Update the Q based on the result\n",
    "        #best_q = np.amax(q_table[state])\n",
    "        #q_table[state_0 + (action,)] += learning_rate * (reward + discount_factor * (best_q) - q_table[state_0 + (action,)])\n",
    "        q_table[state_0 + (action,)] += learning_rate * (reward + discount_factor * q_table[state + (action_new,)] - q_table[state_0 + (action,)])\n",
    "        \n",
    "        # Setting up for the next iteration\n",
    "        state_0 = state\n",
    "        action = action_new\n",
    "\n",
    "        # Render tha maze\n",
    "        if RENDER_MAZE:\n",
    "            env.render()\n",
    "\n",
    "        if env.is_game_over():\n",
    "            sys.exit()\n",
    "\n",
    "        if done:\n",
    "            print(\"Episode %d finished after %f time steps with total reward = %f (streak %d).\"\n",
    "                  % (episode, t, total_reward, num_streaks))\n",
    "            S_Episodes_list.append(episode)\n",
    "            S_timeSteps_list.append(t)\n",
    "            S_TotalReward_list.append(total_reward)\n",
    "            \n",
    "            if t <= SOLVED_T:\n",
    "                num_streaks += 1\n",
    "            else:\n",
    "                num_streaks = 0\n",
    "            break\n",
    "\n",
    "        elif t >= MAX_T - 1:\n",
    "            print(\"Episode %d timed out at %d with total reward = %f.\"\n",
    "                  % (episode, t, total_reward))\n",
    "\n",
    "    # It's considered done when it's solved over 120 times consecutively\n",
    "    if num_streaks > STREAK_TO_END:\n",
    "        break\n",
    "\n",
    "    # Update parameters\n",
    "    explore_rate = get_explore_rate(episode)\n",
    "    learning_rate = get_learning_rate(episode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot SARSA result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEGCAYAAAB7DNKzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAooElEQVR4nO3de5xkdXnn8c9zTlX1bZhp5sIAw+BABBUQAQeCGhXjJUBMSIxZ8RKN2YSYaGLMuru4uokm/ySb3dzUCGgimBjdqEHZgDhqjIQYLsNF5BIEEZhxBmaGYW7d0123Z/8451Sdqq6qrqqe6prT/X2/XvPqqlOnqn5nBs7Tz+/5XczdERERaScYdgNEROTopkAhIiIdKVCIiEhHChQiItKRAoWIiHSUG3YDBmHt2rW+adOmYTdDRCQz7rrrrj3uvq7Va0syUGzatImtW7cOuxkiIplhZk+0e01dTyIi0pEChYiIdKRAISIiHSlQiIhIRwoUIiLSkQKFiIh0pEAhIiIdLcl5FFnx+J4pntg7zStPbznHhdsee4aVo3nOOHFl7dg9Tz7L4WKFlz53be3Ytr3TfPGu7WjJ+KXpkheewAtOqP83cNcTe/n2w7vnnHfMaJ5zT57krA2rGM2H837u0wdm2LHvMABVd3YfLLJz/2GenSoeucbLohofyfGuV/7YEf9cBYoh+utbf8gX7trGAx+5mDCwhteK5Sq/dt1WHPiHX38JZ5y4ku9u28dbPnk7z1kzzs2/84rauX93+xNc/e3HMEOWGHe49juP86XfeCmnrT+GrY/v5S2fup1iuTrn3zv5PaEQBpy5YSWbn3MsZ564inwY4Dj7pkvs3H+YJ56Z5p4n9/GjOEi0ov+WsmntihEFiqVmqlhmplRl295pNq2daHjtOz/Yw8HZMqP5gHdeewd//qZzec/f383hUoVDs+WGcw/NlFm7osDWD712MZsvi2Db3mne8Inv8MufvpM/+cWz+c3P3s2GyTG+9BsvZfVEoeHcPYdmufuJZ7kr/nPdvz9BsVxtOCcMjBNWjXLOxkl+5SdO4dS1E2BgRDeZE1aNsnqigClSSIoCxRDNlqL/ib//9ME5gWLLg08zUQj53BUX8tZP3s6bP3kbk+N5Xn7aWh7YcaDh3OlihfGC/imXoo2rx/n0L5/Pf7r633nLJ29nzUSBa995/pwgAdGN/nVnHs/rzjwegNlyhW17p6nGmcbK0TzrjhmZk72KzEfF7CGaKVUAeGTXoYbj1arz9Qef5qLnHcfZJ01y9dtfzAtOWMmn3r6ZM05cyVRTRjE1W2a8MH+ftGTTWRtW8VdvPY8XnLCSv/7l83nOmon53wSM5EKee9wxnL4++nP8qlEFCemLfg0dotlyPaNIu2fbPnYfnOV1Z64H4KU/tpavvvflAHznB88wW65SrlTJhVGcny5WmBjRP+VSdtHzjuOi5x037GbIMqWMYoiSjOLhpxoDxZYHnyIfGq96/twbQ5I5TMfvhajWoYxCRAZFgWKIZsrRzf6x3VOUK1F24e5seeBpLjx1DStH83Pek2QO07P1QDE9W2FCNQoRGRAFiiGaKUVDHIuVKk/snQbg0V2H+OGeqVpBslmSOUwV63WKqWKZ8RFlFCIyGAoUQzRbrvDcdSsAeCSuU9z4vZ2YwevOWN/yPUnm0JBRFJVRiMjgKFAM0UypypknrsQMHn7qEO7O9ff8iJecuob1K0dbvifJHNIZxaFZZRQiMjgKFEM0U6owOV5g47HjfH/XQe5+8lmeeGaaN5x3Utv31DKKOFCUKlWK5aoyChEZGAWKIZotVRnNh5y+/hgeefogX7r7R4zmAy4+q3V9AmAiySjirqfpYvRTo55EZFD0a+iQVKtOsVJlJBdw+voV/MvDu3hq/wwXn3k8KzrMiRhvyiiSn5pHISKDorvLkCST7UbzIaesnaBcdQ7MlDt2O0G96ynJKJKfyihEZFDU9TQkyWS70XzA6euPAeC4Y0Z4WWr58FbGkgl3zRmFahQiMiAKFEOSTLYbzYecum6CiULIG1980rxr8RRyAYUwYKrYlFFo1JOIDIh+DR2SmXjl2JFcwGg+ZMvvvpJ1K0a6eu/4SMj0rDIKEVkcyigW6IEd++es+d+N2VRGAbBhcoxCrrt/jolCrp5RxD8nlFGIyIAoUCzAdLHMz33837jq2z/o+b1JRjGa7/2fYGIkrC01nmQW2o9CRAZFgWIBZkpVShXnq/c/1cd744wi13smMN4qo1CgEJEBUaBI+cLWbdzz5LNdn1+Jtw57aOcBtsWL+nUrCRQj+d4DxUS6RpFkFOp6EpEBUaBI+b2vPMBN39vZ9flJoAD42gO9ZRXJPIqRLusSac0ZRSEXkA/1TykigzHUu4uZXWxmD5vZo2Z2ZYvXLzKz/WZ2b/zn9wbZnlxolCo+/4mxcrVexN7y4NM9fVd9HkUfGUUhbJhHMaHJdiIyQEPr2DazEPg48FpgO3Cnmd3g7g82nfqv7v76xWhTIQwabv7zSU496dgxtj6+l2cOzbKmyyGuswsoZo+P5BpmZquQLSKDNMyM4gLgUXd/zN2LwOeBy4bYniijKPeeUVz6whOoOnzzoV1dv3emfAQzCtUnRGSAhhkoNgDbUs+3x8eavcTMvmtmXzWzM9t9mJldYWZbzWzr7t27+2pQLggo9ZBRJDWKF25YxYbJMbY82H2dYra0sBrFdLFCtepMFZVRiMhgDTNQtFqrovnX+buB57j7i4CPAl9u92Hufo27b3b3zevWreurQYVc0FONouLRufnQeO0Z67nlkT2UKt0FmgXVKOIM4nCpwvSsMgoRGaxhBortwMbU85OAHekT3P2Aux+KH98E5M2s86p5C5ALjHKXN3qAchxUwiDgzBNXUixX2bHvcFfvnSlXCAPra7RSkkFMFcvKKERk4IYZKO4ETjOzU8ysAFwO3JA+wcyONzOLH19A1N5nBtWgfNhjRlFNAgVsXD0OwJNdzqeYKVUZ7aPbCeoZxfRshalZjXoSkcEa2q+i7l42s/cAXwNC4G/c/QEze1f8+lXAG4HfMLMycBi43N27v5P3KB9a111HUO96CoOAk+NAsW1vdxnFbLnS12Q7aMwopotlxrVpkYgM0FDvMHF30k1Nx65KPf4Y8LHFak+ux+GxSUaRC4z1K0cphMHiZBS1Xe4qTM1WlFGIyEBpOm9KvtfhsXE3VWBGGBgbjh1j27PdBopKX4VsqC/XcXCmxOGSahQiMlgKFCn5sLfhsdW46ykXRgO4Nq4e73rNp5lSte+upySj2HOoGD3XqCcRGSAFipR8GNSyhG6Ua8XsOFAcO9a26+lwsVKbJAdRjaKfWdlQ3x9798HZ+LkyChEZHAWKlFzQYzE7zj7CaGAWJ68eZ990iQMzpTnnvv+L3+V9//fe2vPZUrWvyXYAE3HxOgkUyihEZJAUKFKi4bH9zKOoBwqgZffT0/tneOKZ+vGZ8gJqFElGcUgZhYgMngJFSj60WndSN1rVKKB1oChVnQOH65nGTKnS16ZFEC37EQZWzygUKERkgBQoUnJhQKmH/a9rNQprDhRz51KUylUOzNRrFDOlat81CjNjvBCyJ6lRqOtJRAZIgSIlHxqlHjKKSlMxe9VYnlVj+ZYF7XK1yqHZcm2JkNlyhZE+MwqIsghlFCKyGBQoUnqtUdQn3NX/Gjeubj3yKVka5FC8delCMgqIsoiDyTaomnAnIgOkQJGSC/obHpuKE5y8erzlpLskAB04nASK/ovZ0JhFTGgJDxEZIAWKlHyu1+GxLTKKY8fZvvcw1aYurFqgmCnh7syW+59wB41ZhDIKERkkBYqUfNBf11NSo4CooF2sVNkV1w8SSaZy4HCJ2XL/mxYlVsRZRBjYgj5HRGQ+usOk5EKj6vUAMJ9WgeLkNsuNF1MZRX2/7AVkFHGgGC+ExCuxi4gMhAJFSrKJULdZRfMSHtB+X4p6RlFO7Zfd/19/smLsCtUnRGTAFChS8vHEuW4n3VVTy4wnNkyOYTZ30l26RlHbBnUBw2OT2diqT4jIoClQpCRF6W63Q22VURRyAWsmRth1cKZ2zN1r56ZrFAsa9RRPstOIJxEZNAWKlHxcFC52GShqiwIGjTWCkVxAMbWvRXp71QMz5VpGsZAitDIKEVksChQp+fiG3+1ciiSehDY3UKTrHOld8w4cLjFzBIrZtYxCs7JFZMAUKFKSYnb3gaKKGQRNGUXzDO/0rnkNNYqFzMxOMgp1PYnIgClQpCSrwHbb9VSuekMhO9E8cS+9a97+I1WjKIQNP0VEBkWBIqWWUXS5HWrFfU59IvmcYiVdo0h3PR2hGkVtHoUyChEZLAWKlNo8inKXXU8Vn1OfSD4nvVx50pUVWHPX0xHIKLTEuIgMmAJFStL1VGqTUTTPjShXW2cUhaYaRdKVtXqiEBWzkyU8jkSNQhmFiAyYAkVKoUMx+5GnD/Ly//Ut7nny2dqxqju5cO5fYT60hjpH8nlrJkaYKlaYjpcHPzLzKJRRiMhgKVCkJIXpVkt47NwfTaDbO1WsHStXnaBN11Mx1fWUfN6aFQWA2oZDC6lRnLBqjJ86cz0/fsqavj9DRKQb6rdIyXVY62kqzgLSk+cqlXajnpqGx9YCxQgAuw7OYlbPYPpRyAVc/Uub+36/iEi3lFGkdOp6mipGBej0iKjONQpvOA9gzUSUUew6OMNoTqu+ikg2DDVQmNnFZvawmT1qZle2eN3M7C/j1+8zs/MG2Z5aMbtDRpFegjyqUbTqemqaRxF3Q9UDxeyCJtuJiCymod2tzCwEPg5cApwBvNnMzmg67RLgtPjPFcAnBtmmfG3U09yM4lCLrqdytcPw2IYJd9F7VqdqFAspZIuILKZh/lp7AfCouz/m7kXg88BlTedcBnzGI7cBk2Z2wqAaVJ9H0SmjqL9WqVbbT7grt8ooohrFwZmydqUTkcwY5t1qA7At9Xx7fKzXc46YXIeZ2dNxjaKhmN2uRpFrrlE0jnqChQ2NFRFZTMMMFK0quc19Pt2cE51odoWZbTWzrbt37+6rQbWupxbF7KTrKb1XRbtA0VyjSJbzmBzLk5w+okAhIhkxzECxHdiYen4SsKOPcwBw92vcfbO7b163bl1fDcoH8w+PTe9+125RwEIYUq56bQe8JLgUcgHHjOYBGFXXk4hkxDDvVncCp5nZKWZWAC4Hbmg65wbg7fHopwuB/e6+c1ANSkYwdR4eO3/XUz7XuBRIEnjyYcCqsShQKKMQkawY2oQ7dy+b2XuArwEh8Dfu/oCZvSt+/SrgJuBS4FFgGnjnINuUFLNbLTM+1UPXU6E2cc8ZydW7snKhsXIs+itXRiEiWTHUmdnufhNRMEgfuyr12IF3L1Z7Om1c1K7rqd2oJ4hHO42kMoogYGXS9aSMQkQyQr/WpoSBEVjrUU/1YnZqwl3VyQWtFgVszEyS9+Rz6UChv3oRyQbdrZrkwqBl19N0ixpFuepztkGF+uipZC5F8nm5oN71NJJTRiEi2aBA0SQfWMuup3bDY1uOeso1jp6qZRShMgoRyZ62NQoz+91Ob3T3Pz3yzRm+fC5oCAYQ3fCT7KCrUU+pYnby/sCirq2VY6pRiEi2dCpmHxP/fB5wPvWhqz8D3DLIRg1TLmjc7xpgerZSe1yuNo16arPWE9QzilK1Wju2cjQe9aRAISIZ0TZQuPtHAMxsC3Ceux+Mn38Y+MKitG4I8qHNySgOFcu1x+WmpTnCNqvHQr02USp7PVAk8yg0PFZEMqKbu9XJQDH1vAhsGkhrjgLNK79CfWgsNHY9VZ02M7MbFxcsV6u14KEJdyKSNd3Mo/hb4A4zu55onaWfB64baKuGKBfanGXGD6UDRXov7Gq1dddTbm6NIteUUWjCnYhkRcdAYdEWbJ8Bvgq8PD78Tne/Z9ANG5ZCOLeYna5RpINIpTJfMTtZwsNrWcbaeDvUyfHCnPeJiByNOgYKd3cz+7K7vxi4e5HaNFS50OasHpvOKCrpZcY77HAHqRpFpVo775S1E3zhXS/h3I2TR7rpIiID0U3/x21mdv7AW3KUyAXtaxQrRnJzRj0FLbqeRlrMo0iyDIDzN62udUWJiBztuqlRvAr4dTN7Apgi2iPC3f3sgbZsSAotitnT8ainVWP5rpYZn9v1VG15nohIFnQTKC4ZeCuOIrnQGrYxBTgU1yhWjeUbhsdGE+7ar/VUKteL2QUVr0Uko+YNFO7+BICZHQeMDrxFQ5YPg9reE4mp2TKBRV1PpTnLjLf+DEgtCtgm8xARyYJ5f801s581s0eAHwLfBh4nGgW1JOVDq81/SByaLTNRyJELjcqcZcbn/hUmI5xqiwKWqw01ChGRLOnm7vWHwIXA9939FODVwL8NtFVDlAuCOcuMTxfLTIzkyIVB4/DYdjWKZIe7VEahQCEiWdXN3avk7s8AgZkF7v4t4JzBNmt4okUBG4fHTs1WmBgJyQdGJQ4i7h6Neuq2mN1iGK2ISBZ0U8zeZ2YriBYC/KyZ7QLK87wns/KBzdmP4tBsmRUjOcLUEuRJYtEqo0iOFWszs5VRiEh2dXP3uoxov+r3ATcDPyBaQXZJyoVz96OYmi0zXsg1rAOVdE+1mpltZg3DbEuV+lpPIiJZ001G8SbgX939EZbwGk+JlosCFitsmCwQBvVidlLGaDeaKV0UL1dUzBaR7OomUGwC3mZmm4CtwL8SBY57B9es4Wm3euyKkZAgqC/v0SmjgKjWkV7rqdXe2iIiWTDv3cvdf8/dfxI4E7gV+K/AXYNu2LDkQ2uYfQ1RoJgYyZEPglpGkfxsGyjCIFWjqFLIqetJRLJp3ozCzD4EvAxYAdwDvJ8oq1iSci27nqJAcWi2XMskkkDRruupuUahjEJEsqqbrqc3EI1yupFowt1t7j4z0FYNUT7uXnJ3zKLd7mZKVSYKOWZLlVrXUxIoWg2PhbhG0WZRQBGRLOmm6+k8okl2dwCvBb5nZrcOumHDktzQk+6nZDmPiZGQMNX1VJ4no0jXOooa9SQiGdZN19NZRJsWvRLYDGxjiXc9QZIF1JcYnxjJNWQJ9RpF61hbyAUUy/WgooxCRLKqm66nPyaabPeXwJ3uXhpsk4Yr+c2/VK0yRlhbYjxawsNaFLPbfU6UUVSr0QxuzcwWkazqZvXYnzazMeDkpR4kIL1EeJQ5JEuMr4i7nsrVqH5Rni+jCAOK5SqluPitjEJEsqqb1WN/BriXaFY2ZnaOmd2wkC81s9Vm9nUzeyT+eWyb8x43s++Z2b1mtnUh39mt5Df/Wo0i6Xoq5MgH9deqPk+NIhd1UyXFb9UoRCSruvk198PABcA+gHii3aYFfu+VwDfd/TTgm/Hzdl7l7ue4++YFfmdXmhf0S9cowvhmX6l6bZmPVluhJp9TqlQpV5RRiEi2dXP3Krv7/iP8vZdRXw7kOuDnjvDn961Wo6gko55SxeygHkTmm0eRTLhLFhjUHtkiklXd3L3uN7O3AKGZnWZmHwW+s8DvXe/uOwHin8e1Oc+BLWZ2l5ld0ekDzewKM9tqZlt3797dd8OSiXFJJpDUKCZGwlq3VKXqVOKup7BNl1KhllF4/FxdTyKSTd0Eit8iWr5jFvgcsB9473xvMrNvmNn9Lf5c1kP7XhbP47gEeLeZvaLdie5+jbtvdvfN69at6+ErGjVvY5p0Pa0YydWyh1LFa/tShG27nqwhUGhmtohkVTejnqaBD8Z/MLPnAx8Dfm2e972m3Wtm9rSZneDuO83sBGBXm8/YEf/cZWbXE9VKbpmvzQuRdD0lN/jp2TJmMJYP63MsqukA0KFGUa6mup6UUYhINrX9NdfMzjazLXEW8Idmtt7MvgR8A3hwgd97A/CO+PE7gK+0+P4JMzsmeQy8Drh/gd87r3wqGEDU9TRRyGFmtQUAy5VU11OH1WOLFa99TkE1ChHJqE53r08Cfw/8ArAHuBt4DHiuu//ZAr/3j4DXmtkjRMuC/BGAmZ1oZjfF56wHbjWz7xItH3Kju9+8wO+dV/KbfzKrOlo5NgRS2UY8iQ7aB4qkRlGKP0fFbBHJqk5dTyPufm38+GEzez9wpbtXFvql8R7cr25xfAdwafz4MeBFC/2uXjVnFFPFMhOF6K8pXeguz7vMeDyPojbhTl1PIpJNnQLFqJmdCyR3uEPA2WZR9dbd7x5044ah1TyKiZEkUKQm3FU7F6nztYxC8yhEJNs6BYqdwJ+mnj+Veu7ATw6qUcOUHtkEMDVbqXU9pRcMLNeWGW/9OVGg8NTMbAUKEcmmtoHC3V+1mA05WuRTwQDg4GyZDZOjQDqjSE+4a796LFBbVFCjnkQkq/RrbpP6zOyoy+jA4RKrxgpA4zpQ89UoklFOh0uVhuciIlmju1eT5hrF/sMlVo3lgXr2kCwfDp2L2RB1XYEyChHJLgWKJukd7kqVKodmy0yOx4EivSjgfGs9NXU9qUYhIlnVtkZhZud1euNSHfWUS3U9HTgcbb9RzyhSE+6SJTw6zMyGekaR1xIeIpJRnUY9/Z8Ory3ZUU/1FWKdfXGgqGUUQT3biHum5q1RTJfijCKnricRySaNemqS3NBLlSr7ppsyito6UNWuM4rppEahjEJEMqqbPbMxs7OAM4DR5Ji7f2ZQjRqm9Ozr5q6n+n7aXdQo4nOnixr1JCLZNm+gMLPfBy4iChQ3ES35fSuwJANFeuOifYeLAEyOR8Njk/2xK6l5FEGXxWyNehKRrOrm19w3Eq3L9JS7v5No/aWRgbZqiMyMXBCt07S/ueupYT+KzhlFrUYRZxQa9SQiWdXN3euwu1eBspmtJNo74tTBNmu4cqFRrtaL2StHc7Xj0Dg8dt4aRW14rDIKEcmmbmoUW81skmjZ8buIFge8Y5CNGrZkQb9901WOGcnV1nhK1y/mXxSwXqMIA8Pa7IQnInK062aHu9+MH15lZjcDK939vsE2a7iSQDE9W2FVPDQ2Ol7veqotCtjm/p9PdT0pmxCRLJu368nMvpk8dvfH3f2+9LGlKBcY5XgexWQqUCTdTJV446JOmUJ6UUBNthORLOs0M3sUGAfWmtmx1PelWAmcuAhtG5p8GFCsVBvWeUqOA5SqVSrubesT6XOni5XaCCgRkSzq1PX068DvEAWF9HIdB4CPD7BNQ5cP44xiusjzj19ZO17LKOJRT2GHukO6RrFmIhxsg0VEBqjTzOy/AP7CzH7L3T+6iG0aunwYUK5GGcXKVEZRGx5bdcoVbzs0FupdT5Wqa2isiGRaN6Oerjaz3wZeET//F+Bqdy8NrFVDlgsDimVnf1ONIpljUa5UqboTdihSp2diq5gtIlnWTaD4KyAf/wT4JeATwK8OqlHDlg+NA4dLlCreUKOAqPspmkdRnafrKWj5WEQkazoVs3PuXgbOd/cXpV76ZzP77uCbNjz5MGDPoVkAJpsCRbIXdjLqqdNnJHIKFCKSYZ3uYMmkuoqZ/Vhy0MxOBSoDbdWQ5QJjdxIoxltlFNFaT51qFOnupoK6nkQkwzp1PSV3t/cD3zKzx+Lnm4B3DrJRw1bIBRyciZbeWDkno7Da6rHtFgSEqJ6RD41SxZVRiEimdQoU68zsd+PHVwMhMEW01Pi5wLcG3LahSWcKk2OFpteCeD+KzhkFJN1UmpktItnWKVCEwArqmQXxc4BjBtaio0A6A1jVouupHGcUnWoUkNQpKipmi0imdQoUO939DxatJUeR9NDWucXsaDJetetAoVFPIpJtne5gy7a/JFlOPBcY44XGWdX14bFe28ionULqc0REsqrTne7Vg/pSM/tFM3vAzKpmtrnDeReb2cNm9qiZXTmo9jRLlg6fHM/PWfQvWVm2qxpFPDtbaz2JSJa1vYO5+94Bfu/9wBuAW9qdYGYh0ZpSlxBtw/pmMztjgG2qKeSiANA82Q7qmxpV5hn1BKmuJ2UUIpJh3czMPuLc/SFgvs18LgAedffH4nM/D1wGPDjo9iUZRatAEQYB5WpUo+hm1BNowp2IZNvRfAfbAGxLPd8eH2vJzK4ws61mtnX37t0L+uLkBj85Xpj7WrzWU7lanbeYndQoVMwWkSwbWEZhZt8Ajm/x0gfd/SvdfESLY97uZHe/BrgGYPPmzW3P60Yy76F1RhF1PeHt98tOJCvIah6FiGTZwAKFu79mgR+xHdiYen4SsGOBn9mVXIdAkQ8DpovRrO2RfOe/Pg2PFZGl4Gi+g90JnGZmp5hZAbgcuGExvrje9dS5mN3tPIqcMgoRybChBAoz+3kz2w68BLjRzL4WHz/RzG4CiFeufQ/wNeAh4B/c/YHFaF9yg2856ineT7vinXe4S39OQRmFiGTYsEY9XQ9c3+L4DuDS1PObgJsWsWlAvabQMqMIot3vArcuahRWe4+ISFYNJVAc7ToOj42X8AiD+buUajWKnLqeRCS7FChaqI96ajM8tupgEHTZ9ZRXRiEiGaZA0ULHGkUYLTNuFnQ94U7DY0UkyxQoWnjF6ev41Z84hVPWTsx5LRdnFFbpYVFAFbNFJMMUKFo4cXKMD72+9bJSyfDYMOh+CQ+NehKRLFOg6FEuiFaPDQObf1HAnOZRiEj26VfdHuXi/Si63Qo1/VNEJIt0B+tRVMzubmZ2fVFAZRQikl0KFD2KitnVnpbwUEYhIlmmO1iPcqFRdShWqtqPQkSWBd3BepTc/IvlLvajSJYZ1w53IpJhChQ9SgeH+WsU2jNbRLJPd7Ae5XoIFPnaooDKKEQkuxQoepS+6Wt4rIgsB7qD9ShdmJ5vwt2LTprklaevY1OLpUBERLJCM7N7lJ4TMV9GsXH1ONf9ygWDbpKIyEApo+hReiHA+RYFFBFZCnSn61E6o9CEaxFZDhQoetQwPFZFahFZBnSn61F6/2sNexWR5UCBokeNXU8KFCKy9ClQ9KiXmdkiIkuBAkWP0pPntCGRiCwHChQ9SmcRgbqeRGQZUKDoUS8T7kRElgIFih7lGibcKVCIyNKnQNEjFbNFZLkZSqAws180swfMrGpmmzuc97iZfc/M7jWzrYvZxnbSxWwFChFZDoa1KOD9wBuAq7s491XuvmfA7ela2LDMuBIyEVn6hhIo3P0hAMvgqKF0MVtxQkSWg6P9VufAFjO7y8yuGHZjoHE/CmUUIrIcDCyjMLNvAMe3eOmD7v6VLj/mZe6+w8yOA75uZv/h7re0+b4rgCsATj755L7a3I1etkIVEVkKBhYo3P01R+AzdsQ/d5nZ9cAFQMtA4e7XANcAbN682Rf63e0oUIjIcnPU9p2Y2YSZHZM8Bl5HVAQfKq0eKyLLzbCGx/68mW0HXgLcaGZfi4+faGY3xaetB241s+8CdwA3uvvNw2hvWnp9J2UUIrIcDGvU0/XA9S2O7wAujR8/BrxokZs2r5yW8BCRZeao7Xo6WqW7ngIFChFZBhQoehQGRjL9QxmFiCwHChR9SAKEahQishwoUPQh6X5SoBCR5UCBog9JQVuBQkSWAwWKPiRdT1rCQ0SWA93p+pCs9xRmcFFDEZFeKVD0oVbMDhUoRGTpU6DoQ1Kj0PBYEVkOFCj6kI9rE4G6nkRkGVCg6EMYKKMQkeVDgaIPuTDATEt4iMjyoEDRh1xgGvEkIsuGAkUfcqFpsp2ILBsKFH3IB4HqEyKybChQ9CEMTPUJEVk2FCj6kAtNGYWILBsKFH3IBUaodZ5EZJnQ3a4PuTAg1N+ciCwTut31IR+aVo4VkWVDd7s+5IJAw2NFZNnIDbsBWfSWHz+ZV5y+btjNEBFZFAoUfbjw1DXDboKIyKJR15OIiHSkQCEiIh0pUIiISEcKFCIi0pEChYiIdKRAISIiHSlQiIhIRwoUIiLSkbn7sNtwxJnZbuCJPt++FthzBJszTEvpWkDXczRbStcCS+t6ur2W57h7yyUnlmSgWAgz2+rum4fdjiNhKV0L6HqOZkvpWmBpXc+RuBZ1PYmISEcKFCIi0pECxVzXDLsBR9BSuhbQ9RzNltK1wNK6ngVfi2oUIiLSkTIKERHpSIFCREQ6UqCImdnFZvawmT1qZlcOuz29MrONZvYtM3vIzB4ws/fGx1eb2dfN7JH457HDbmu3zCw0s3vM7J/i51m+lkkz+6KZ/Uf8b/SSrF6Pmb0v/m/sfjP7nJmNZulazOxvzGyXmd2fOta2/Wb2gfi+8LCZ/dRwWt1em+v5k/i/tfvM7Hozm0y91vP1KFAQ3ZCAjwOXAGcAbzazM4bbqp6Vgf/i7i8ALgTeHV/DlcA33f004Jvx86x4L/BQ6nmWr+UvgJvd/fnAi4iuK3PXY2YbgN8GNrv7WUAIXE62ruVa4OKmYy3bH/8/dDlwZvyev4rvF0eTa5l7PV8HznL3s4HvAx+A/q9HgSJyAfCouz/m7kXg88BlQ25TT9x9p7vfHT8+SHQj2kB0HdfFp10H/NxQGtgjMzsJ+GngU6nDWb2WlcArgL8GcPeiu+8jo9dDtIXymJnlgHFgBxm6Fne/BdjbdLhd+y8DPu/us+7+Q+BRovvFUaPV9bj7Fncvx09vA06KH/d1PQoUkQ3AttTz7fGxTDKzTcC5wO3AenffCVEwAY4bYtN68efAfwOqqWNZvZZTgd3Ap+OutE+Z2QQZvB53/xHwv4EngZ3AfnffQgavpUm79i+Fe8OvAF+NH/d1PQoUEWtxLJPjhs1sBfAl4Hfc/cCw29MPM3s9sMvd7xp2W46QHHAe8Al3PxeY4ujummkr7ru/DDgFOBGYMLO3DbdVA5Xpe4OZfZCoW/qzyaEWp817PQoUke3AxtTzk4jS6UwxszxRkPisu/9jfPhpMzshfv0EYNew2teDlwE/a2aPE3UD/qSZ/R3ZvBaI/vva7u63x8+/SBQ4sng9rwF+6O673b0E/CPwUrJ5LWnt2p/Ze4OZvQN4PfBWr0+Y6+t6FCgidwKnmdkpZlYgKvbcMOQ29cTMjKgP/CF3/9PUSzcA74gfvwP4ymK3rVfu/gF3P8ndNxH9W/yzu7+NDF4LgLs/BWwzs+fFh14NPEg2r+dJ4EIzG4//m3s1UT0si9eS1q79NwCXm9mImZ0CnAbcMYT29cTMLgb+O/Cz7j6deqm/63F3/YmC7aVEowN+AHxw2O3po/0/QZRC3gfcG/+5FFhDNIrjkfjn6mG3tcfrugj4p/hxZq8FOAfYGv/7fBk4NqvXA3wE+A/gfuBvgZEsXQvwOaL6SonoN+z/3Kn9wAfj+8LDwCXDbn+X1/MoUS0iuRdctZDr0RIeIiLSkbqeRESkIwUKERHpSIFCREQ6UqAQEZGOFChERKQjBQqRNsysYmb3pv50nE1tZu8ys7cfge993MzWLvRzRI4UDY8VacPMDrn7iiF87+NEq7PuWezvFmlFGYVIj+Lf+P/YzO6I/zw3Pv5hM3t//Pi3zezBeD+Az8fHVpvZl+Njt5nZ2fHxNWa2JV4w8GpS6/GY2dvi77jXzK62aI+O0MyujfeD+J6ZvW8Ifw2yjChQiLQ31tT19KbUawfc/QLgY0Qr3Ta7EjjXo/0A3hUf+whwT3zsfwCfiY//PnCrRwsG3gCcDGBmLwDeBLzM3c8BKsBbiWZ5b3D3s9z9hcCnj9QFi7SSG3YDRI5ih+MbdCufS/38sxav3wd81sy+TLRkB0TLrPwCgLv/c5xJrCLaq+IN8fEbzezZ+PxXAy8G7oyWVWKMaLG6/wecamYfBW4EtvR5fSJdUUYh0h9v8zjx00S7Jr4YuCve5KfTEs+tPsOA69z9nPjP89z9w+7+LNEuef8CvJvGzZ1EjjgFCpH+vCn189/TL5hZAGx0928Rbb40CawAbiHqOsLMLgL2eLRnSPr4JUQLBkK0ON0bzey4+LXVZvaceERU4O5fAv4n0ZLlIgOjrieR9sbM7N7U85vdPRkiO2JmtxP9svXmpveFwN/F3UoG/Jm77zOzDxPtcncfME19WeuPAJ8zs7uBbxMt5Y27P2hmHwK2xMGnRJRBHI4/J/lF7wNH7IpFWtDwWJEeafiqLDfqehIRkY6UUYiISEfKKEREpCMFChER6UiBQkREOlKgEBGRjhQoRESko/8PCxNH2gmcYVsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# importing the required module\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# plotting the points\n",
    "plt.plot(S_Episodes_list, S_TotalReward_list)\n",
    " \n",
    "# naming the x axis\n",
    "plt.xlabel('Episodes')\n",
    "# naming the y axis\n",
    "plt.ylabel('Total Reward')\n",
    " \n",
    "# giving a title to my graph\n",
    "#plt.title('My first graph!')\n",
    " \n",
    "# function to show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Replay(object):\n",
    "    #memory for training the DQN\n",
    "    def __init__(self):\n",
    "        self.max_size = 100\n",
    "        self.transitions = []  # (old state, new state, action, reward)\n",
    "\n",
    "    def store(self, s0, s, a, r):\n",
    "        self.transitions.append((s0, s, a, r))\n",
    "        if len(self.transitions) > self.max_size:\n",
    "            self.transitions.pop(0)\n",
    "\n",
    "    def sample(self):\n",
    "        return self.transitions[random.randint(0, len(self.transitions) - 1)]\n",
    "\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        self.layer1 = nn.LSTM(2, 4, num_layers=32)\n",
    "        self.layer2 = nn.LSTM(4, 8, num_layers=64)\n",
    "        self.layer3 = nn.LSTM(8, 16, num_layers=64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc = nn.Linear(16, 4)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, h = self.layer1(x)\n",
    "        x=self.relu(x)\n",
    "        x,h=self.layer2(x)\n",
    "        x=self.relu(x)\n",
    "        x,h=self.layer3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc(x)\n",
    "        # x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "    def test(self):\n",
    "        pass\n",
    "\n",
    "    def select_action(self, state, er, device):\n",
    "        # Select a random action\n",
    "        if random.random() < er:\n",
    "            action = env.action_space.sample()\n",
    "        # Select the action with the highest q\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                state = torch.FloatTensor([state[0], state[1]]).view(1, 1, len(state)).to(device)\n",
    "                val, action = self.forward(state)[0][0].max(0)\n",
    "                action = action.item()\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instantiating the learning related parameters\n",
    "discount_factor = 0.99\n",
    "update_target = 5\n",
    "\n",
    "num_streaks = 0\n",
    "\n",
    "# Render the maze\n",
    "env.render()\n",
    "dqn = DQN()\n",
    "device = torch.device('cpu')\n",
    "dqn = dqn.to(device)\n",
    "target = DQN()\n",
    "target = target.to(device)\n",
    "dqn_opt = optim.Adam(dqn.parameters())\n",
    "dqn_opt.zero_grad()\n",
    "replay = Replay()\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "for episode in range(NUM_EPISODES):\n",
    "    # Reset the environment\n",
    "    obv = env.reset()\n",
    "\n",
    "    # the initial state\n",
    "    s0 = state_to_bucket(obv)\n",
    "    total_reward = 0\n",
    "    total_loss = 0\n",
    "\n",
    "    # Update parameters\n",
    "    explore_rate = get_explore_rate(episode)\n",
    "    learning_rate = get_learning_rate(episode)\n",
    "\n",
    "    for t in range(MAX_T):\n",
    "        # Select an action\n",
    "        action = dqn.select_action(s0, explore_rate, device)\n",
    "\n",
    "        # execute the action\n",
    "        obv, reward, done, _ = env.step(action)\n",
    "\n",
    "        # Observe the result\n",
    "        s = state_to_bucket(obv)\n",
    "        total_reward += reward\n",
    "\n",
    "        # store the transition\n",
    "        replay.store(s0, s, action, reward)\n",
    "\n",
    "        # update the dqn\n",
    "        r_s0, r_s, r_a, r_r = replay.sample()\n",
    "        r_s0 = torch.FloatTensor([r_s0[0], r_s0[1]]).view(1, 1, len(r_s0)).to(device)\n",
    "        r_s = torch.FloatTensor([r_s[0], r_s[1]]).view(1, 1, len(r_s)).to(device)\n",
    "        dqn_output =dqn.forward(r_s0)\n",
    "        target_output=target.forward(r_s)\n",
    "        dqn_opt.zero_grad()\n",
    "        l = loss(dqn_output, target_output)\n",
    "        l.backward()\n",
    "        dqn_opt.step()\n",
    "        total_loss+=l.item()\n",
    "\n",
    "        # update the target network\n",
    "        if episode % update_target == 0:\n",
    "            target.load_state_dict(dqn.state_dict())\n",
    "\n",
    "        # Setting up for the next iteration\n",
    "        s0 = s\n",
    "\n",
    "        # Render tha maze\n",
    "        if RENDER_MAZE:\n",
    "            env.render()\n",
    "\n",
    "        if env.is_game_over():\n",
    "            sys.exit()\n",
    "\n",
    "        if done:\n",
    "            print(\"Episode %d finished after %f time steps with total reward = %f, loss = %f (streak %d).\"\n",
    "                  % (episode, t, total_reward, total_loss, num_streaks))\n",
    "\n",
    "            if t <= SOLVED_T:\n",
    "                num_streaks += 1\n",
    "            else:\n",
    "                num_streaks = 0\n",
    "            break\n",
    "\n",
    "        elif t >= MAX_T - 1:\n",
    "            print(\"Episode %d timed out at %d with total reward = %f.\"\n",
    "                  % (episode, t, total_reward))\n",
    "\n",
    "    # It's considered done when it's solved over 120 times consecutively\n",
    "    if num_streaks > STREAK_TO_END:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
